# Fine-Tune-for-Classification-and-NER
Finetuning Transformer based for Indonesian news classification and NER
## Classification
In here, I use IndoBERT, mBERT, and RoBERTa. This work is corresponding with [Comparing-Embedding-Methods](https://github.com/ThomasArtemius/Comparing-Embedding-Methods) repository. 
## NER
In here, I use IndoBERT, sBERT, and mBERT. Each model perform 2 finetuning methods (except IndoBERT, which has partial finetuning): Full finetuning and LoRA. This task is actually corresponding with [Named-Entity-Recognition](https://github.com/ThomasArtemius/Named-Entity-Recognition) repository.
